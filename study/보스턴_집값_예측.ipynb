{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "보스턴 집값 예측.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM72eMm8b3Ik3g2rM2JOUUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uchan21/2022smarkle-AI-study-/blob/main/%EB%B3%B4%EC%8A%A4%ED%84%B4_%EC%A7%91%EA%B0%92_%EC%98%88%EC%B8%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7pw3aDyRboTZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(3)"
      ],
      "metadata": {
        "id": "pPQAhc6ab4AV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/sejongsmarcle/2022_Winter_AiStudy/main/dataset/housing.csv\",delim_whitespace=True,header=None)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8CHeVkmb9e5",
        "outputId": "14942916-cbce-4739-f791-6abc0cdd36a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0     1     2   3      4      5   ...  8      9     10      11    12    13\n",
            "0  0.00632  18.0  2.31   0  0.538  6.575  ...   1  296.0  15.3  396.90  4.98  24.0\n",
            "1  0.02731   0.0  7.07   0  0.469  6.421  ...   2  242.0  17.8  396.90  9.14  21.6\n",
            "2  0.02729   0.0  7.07   0  0.469  7.185  ...   2  242.0  17.8  392.83  4.03  34.7\n",
            "3  0.03237   0.0  2.18   0  0.458  6.998  ...   3  222.0  18.7  394.63  2.94  33.4\n",
            "4  0.06905   0.0  2.18   0  0.458  7.147  ...   3  222.0  18.7  396.90  5.33  36.2\n",
            "\n",
            "[5 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = df.values\n",
        "X = dataset[:,0:13].astype(float)\n",
        "Y = dataset[:,13].astype(float)\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3,random_state = seed)"
      ],
      "metadata": {
        "id": "BxMQLdvXcZBU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(30,input_dim=13,activation='relu'))\n",
        "model.add(Dense(6,activation='relu'))\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "p33sIBczdO4w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'mean_squared_error',\n",
        "              optimizer='adam')\n",
        "model.fit(X_train,Y_train,epochs=200,batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDsKlsrudhWT",
        "outputId": "9d6de8aa-373c-4a1c-cc51-20cfb82da830"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 384.6314\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 100.2575\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 85.9378\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 81.8063\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 77.1717\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 70.4092\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 68.5919\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 65.1732\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 64.0618\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 58.6770\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 56.9624\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 54.9636\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 53.8858\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 51.4370\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 50.4716\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 49.7803\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 54.2051\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 46.5617\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 42.8530\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 42.6048\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 41.9762\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 41.3709\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 40.7717\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 45.6480\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 40.0822\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.9744\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 37.4677\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 35.5751\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 36.2020\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 36.9614\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.4212\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 35.5128\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 35.3332\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 35.0081\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.9613\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.7527\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.8701\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.7857\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.2002\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.2135\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.2624\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 33.0483\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.3040\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.4671\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.2274\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.8913\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.0548\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.4522\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.9925\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 32.7703\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.8056\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.5907\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.2210\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.7992\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.0304\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.5292\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.6020\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.4943\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.8338\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27.8652\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.2420\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.3574\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.3748\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27.4854\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27.5357\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 34.1608\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.3324\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.2327\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.0830\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27.4292\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.3889\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27.1417\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27.5476\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.2533\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.8238\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 30.1856\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 27.7836\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 29.0623\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 25.7975\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 28.4906\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 27.5603\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27.1086\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26.7812\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27.4007\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27.0657\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.8983\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 31.0090\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 30.2063\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 29.7697\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.9606\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.1792\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.0272\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.6681\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26.2626\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26.5904\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.4751\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.2177\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26.1778\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26.8410\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26.8963\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.3509\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27.0296\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26.1673\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 28.5509\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 36.4065\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.8183\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.5059\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.9900\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26.7370\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.6155\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.7395\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.3915\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.8799\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.3548\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.4360\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.0419\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.1445\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.5100\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.1840\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.5308\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.4137\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.6321\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.2572\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.6605\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.8605\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.1199\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.5578\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.3723\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.8100\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.5703\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.6763\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.2672\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.1717\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.2628\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.1898\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.9169\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.3533\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.1763\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.9889\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.8073\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.3912\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.8708\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.7147\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.5023\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.7295\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.2912\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.5595\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.8882\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.8353\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.5842\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.2316\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.0247\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.2485\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.9534\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.5399\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.3775\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.4047\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.5389\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.7454\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.2448\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.0998\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.9794\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.1217\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23.5867\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.3362\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.3191\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.5976\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.7517\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.6205\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.8303\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.8407\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.2232\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.1866\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.7499\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.2975\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.1651\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 19.5551\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.0380\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.2931\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.3022\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.8605\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 19.3468\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.2085\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.8213\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.2085\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18.8214\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18.9085\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.5891\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18.6817\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18.9742\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 21.6318\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18.8602\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18.1093\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20.8184\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 19.1413\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18.4238\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18.3283\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 19.3850\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18.3637\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 17.8474\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f900c469d10>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_prediction = model.predict(X_test).flatten()\n",
        "for i in range(10):\n",
        "  label = Y_test[i]\n",
        "  prediction = Y_prediction[i]\n",
        "  print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label,prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFJM_WF5dx4c",
        "outputId": "a8616473-fe20-4aae-8e9e-3414755b0d0d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실제가격: 22.600, 예상가격: 20.944\n",
            "실제가격: 50.000, 예상가격: 24.598\n",
            "실제가격: 23.000, 예상가격: 25.666\n",
            "실제가격: 8.300, 예상가격: 12.547\n",
            "실제가격: 21.200, 예상가격: 20.025\n",
            "실제가격: 19.900, 예상가격: 20.931\n",
            "실제가격: 20.600, 예상가격: 20.433\n",
            "실제가격: 18.700, 예상가격: 21.408\n",
            "실제가격: 16.100, 예상가격: 17.208\n",
            "실제가격: 18.600, 예상가격: 13.226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LtmEWKAReaMl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(Y_test[0:10],\"o\",c=\"red\",markersize=3)\n",
        "plt.plot(Y_prediction[0:10],\"o\",c=\"blue\",markersize=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "mblzcBCWm46I",
        "outputId": "d968863d-c112-49ac-bec0-d72cbb4125db"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f900c2de5d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
